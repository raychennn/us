import requests
import pandas as pd
import pandas_ta as ta
import yfinance as yf
import asyncio
import traceback
import io
import math  # ç”¨æ–¼ç„¡æ¢ä»¶é€²ä½è¨ˆç®—
from datetime import datetime, timedelta

# ç­–ç•¥åƒæ•¸
import config as cfg

# --- A. è‡ªå‹•ç²å– NASDAQ æ¸…å–® (åš´æ ¼éæ¿¾ç‰ˆ) ---
def get_nasdaq_stock_list():
    """
    å¾ NASDAQ ç²å–æ¸…å–®ï¼Œä¸¦åš´æ ¼éæ¿¾ ETF, ADR, æ¬Šè­‰, ç‰¹åˆ¥è‚¡
    """
    try:
        url = "http://www.nasdaqtrader.com/dynamic/symdir/nasdaqlisted.txt"
        s = requests.get(url).content
        df = pd.read_csv(io.BytesIO(s), sep="|")
        
        # 1. åŸºç¤æ¸…æ´—
        df = df.dropna(subset=['Symbol'])
        df = df[df['Test Issue'] == 'N'] # æ’é™¤æ¸¬è©¦ä»£ç¢¼
        
        # 2. æ’é™¤ ETF
        if 'ETF' in df.columns:
            df = df[df['ETF'] == 'N']
            
        # 3. åˆ©ç”¨åç¨±æ’é™¤ ADR, ç‰¹åˆ¥è‚¡, æ¬Šè­‰
        # è½‰å¤§å¯«ä»¥åˆ©æ¯”å°
        df['Security Name'] = df['Security Name'].str.upper()
        
        # å®šç¾©æ’é™¤é—œéµå­—
        exclude_keywords = [
            ' ADR ', ' ADS ', ' DEPOSITARY ', # ADR ç›¸é—œ
            ' PREFERRED ', ' PFD ',           # ç‰¹åˆ¥è‚¡
            ' WARRANT ', ' WTS ', ' UNIT ',   # æ¬Šè­‰èˆ‡å–®ä½
            ' RIGHTS ',                       # èªè‚¡æ¬Š
            ' ACQUISITION '                   # SPAC ç›¸é—œ
        ]
        
        for kw in exclude_keywords:
            df = df[~df['Security Name'].str.contains(kw, na=False)]

        # 4. ç¬¦è™Ÿé•·åº¦éæ¿¾ (NASDAQ é€šå¸¸ 4 ç¢¼)
        full_list = df['Symbol'].tolist()
        
        # æ¸…é™¤åŒ…å«éå­—æ¯çš„ç¬¦è™Ÿ
        clean_list = [x for x in full_list if x.isalpha()]
        
        print(f"âœ… æˆåŠŸç²å– {len(clean_list)} æª” NASDAQ æœ¬åœŸè‚¡ç¥¨ (å·²æ’é™¤ ETF/ADR/æ¬Šè­‰)")
        return clean_list 
        
    except Exception as e:
        print(f"âŒ ç²å– NASDAQ æ¸…å–®å¤±æ•—: {e}")
        # å‚™æ¡ˆï¼šå›å‚³å¤§å‹ç§‘æŠ€è‚¡
        return ['AAPL', 'MSFT', 'AMZN', 'NVDA', 'TSLA', 'META', 'AMD', 'NFLX', 'GOOGL', 'AVGO']

# --- B. è¼”åŠ©è¨ˆç®—: RS Score ---
def calculate_performance_score(close_series):
    """è¨ˆç®— IBD é¢¨æ ¼çš„ RS Score (40%/20%/20%/20%)"""
    if len(close_series) < 260: return -999
    try:
        c_now = close_series.iloc[-1]
        c_3m = close_series.iloc[-63]
        c_6m = close_series.iloc[-126]
        c_9m = close_series.iloc[-189]
        c_12m = close_series.iloc[-252]
        
        roc_3m = (c_now - c_3m) / c_3m
        roc_6m = (c_now - c_6m) / c_6m
        roc_9m = (c_now - c_9m) / c_9m
        roc_12m = (c_now - c_12m) / c_12m
        
        score = (roc_3m * 0.4) + (roc_6m * 0.2) + (roc_9m * 0.2) + (roc_12m * 0.2)
        return score
    except:
        return -999

# --- B2. Fallen Angel RSï¼šæŒ‡æ¨™è¨ˆç®—èˆ‡ Gate ---

def _safe_div(a, b, default=float("nan")):
    try:
        if b == 0 or pd.isna(b):
            return default
        return a / b
    except Exception:
        return default


def compute_fallen_angel_rs_features(df_stock: pd.DataFrame, qqq_close: pd.Series):
    """\
    Fallen Angel RS Gateï¼ˆvs QQQï¼‰ã€‚

    å›å‚³:
      (pass_gate: bool, features: dict)

    features æœƒåŒ…å«ä½ æŒ‡å®šçš„æ¬„ä½ï¼š
      - leader_peak_excessï¼ˆ%ï¼‰
      - rs_near_high_pctï¼ˆ%ï¼‰
      - rs_dd_vs_price_ddï¼ˆratioï¼‰
      - rs_ma20_slopeï¼ˆ%ï¼‰
    """
    features = {
        "leader_peak_excess": float("nan"),
        "rs_near_high_pct": float("nan"),
        "rs_dd_vs_price_dd": float("nan"),
        "rs_ma20_slope": float("nan"),
    }

    if df_stock is None or df_stock.empty or qqq_close is None or qqq_close.empty:
        return False, features

    close = df_stock["Close"].copy()
    bench = qqq_close.reindex(close.index).ffill()

    aligned = pd.concat([close, bench], axis=1).dropna()
    if aligned.shape[0] < 260:
        return False, features

    close_s = aligned.iloc[:, 0]
    close_b = aligned.iloc[:, 1]

    # RS line
    rs_line = close_s / close_b

    # ---------- A) Leader Peak ----------
    ex3 = (close_s.pct_change(63) - close_b.pct_change(63)).tail(cfg.LEADER_PEAK_LOOKBACK_D)
    ex6 = (close_s.pct_change(126) - close_b.pct_change(126)).tail(cfg.LEADER_PEAK_LOOKBACK_D)

    max_ex3 = ex3.max(skipna=True)
    max_ex6 = ex6.max(skipna=True)
    leader_peak_excess = max(max_ex3 if pd.notna(max_ex3) else -999,
                             max_ex6 if pd.notna(max_ex6) else -999)

    if leader_peak_excess != -999:
        features["leader_peak_excess"] = float(leader_peak_excess * 100.0)

    leader_ok = ((pd.notna(max_ex3) and max_ex3 >= cfg.MIN_PEAK_EXCESS_3M) or
                 (pd.notna(max_ex6) and max_ex6 >= cfg.MIN_PEAK_EXCESS_6M))
    if not leader_ok:
        return False, features

    # ---------- B) Resilience ----------
    lb = cfg.RESILIENCE_LOOKBACK_D
    if aligned.shape[0] < lb + 5:
        return False, features

    price_high = close_s.rolling(lb).max()
    rs_high = rs_line.rolling(lb).max()

    c_now = close_s.iloc[-1]
    rs_now = rs_line.iloc[-1]
    ph_now = price_high.iloc[-1]
    rsh_now = rs_high.iloc[-1]

    price_dd = 1.0 - _safe_div(c_now, ph_now, default=float("nan"))
    rs_dd = 1.0 - _safe_div(rs_now, rsh_now, default=float("nan"))

    rs_near_high_pct = _safe_div(rs_now, rsh_now, default=float("nan"))
    if pd.notna(rs_near_high_pct):
        features["rs_near_high_pct"] = float(rs_near_high_pct * 100.0)

    ratio = _safe_div(rs_dd, price_dd, default=float("inf"))
    if pd.notna(ratio):
        features["rs_dd_vs_price_dd"] = float(ratio)

    # åƒ¹æ ¼å›æ’¤å€é–“
    if pd.isna(price_dd) or not (cfg.MIN_PRICE_DD <= price_dd <= cfg.MAX_PRICE_DD):
        return False, features

    resilience_ok = (pd.notna(rs_near_high_pct) and rs_near_high_pct >= cfg.MIN_RS_NEAR_HIGH_PCT) and \
                    (pd.notna(ratio) and ratio <= cfg.MAX_RS_DD_TO_PRICE_DD_RATIO)
    if not resilience_ok:
        return False, features

    # ---------- C) Turn-up ----------
    rs_ma20 = rs_line.rolling(cfg.RS_MA_LEN).mean()
    if rs_ma20.isna().iloc[-1]:
        return False, features

    rs_ma_now = rs_ma20.iloc[-1]
    rs_ma_prev = rs_ma20.shift(cfg.RS_SLOPE_LOOKBACK_D).iloc[-1]
    rs_ma_slope = _safe_div(rs_ma_now, rs_ma_prev, default=float("nan")) - 1.0

    if pd.notna(rs_ma_slope):
        features["rs_ma20_slope"] = float(rs_ma_slope * 100.0)

    turnup_ok = (rs_now > rs_ma_now) and (pd.notna(rs_ma_slope) and rs_ma_slope > cfg.MIN_RS_MA20_SLOPE)
    if not turnup_ok:
        return False, features

    return True, features


def yf_download_with_retry(tickers, start, end, **kwargs):
    """yfinance.download åŒ…ä¸€å±¤ retry + exponential backoffï¼Œé¿å…å¶ç™¼ç¶²è·¯/ç¯€æµå¤±æ•—ã€‚"""
    last_err = None
    for attempt in range(1, cfg.YF_MAX_RETRIES + 1):
        try:
            return yf.download(tickers, start=start, end=end, progress=False, auto_adjust=True, **kwargs)
        except Exception as e:
            last_err = e
            wait = cfg.YF_BACKOFF_BASE_SEC * (2 ** (attempt - 1))
            print(f"âš ï¸ yfinance ä¸‹è¼‰å¤±æ•— (attempt {attempt}/{cfg.YF_MAX_RETRIES}): {e} ; sleep {wait:.1f}s")
            try:
                import time
                time.sleep(wait)
            except Exception:
                pass
    if last_err:
        raise last_err
    return pd.DataFrame()


# --- C. VCP ç­–ç•¥æª¢æŸ¥é‚è¼¯ (å« Dynamic Gap Reset & 10å¤©è¦–çª—) ---
def check_vcp_criteria(df, qqq_close=None):
    """
    å›å‚³ True/False
    """
    # 0. è³‡æ–™é•·åº¦ (éœ€ > 260 å¤©ç®— RS èˆ‡ 52é€±ä½é»)
    if len(df) < 260: return False
    
    close = df['Close']
    vol = df['Volume']
    high = df['High']
    low = df['Low']
    open_price = df['Open'] # éœ€ç²å– Open è¨ˆç®—è·³ç©º
    
    current_c = close.iloc[-1]
    
    # --- 1. åŸºç¤é–€æª» (Basic Filters) ---
    # è‚¡åƒ¹ > 10 ç¾å…ƒ
    if current_c < cfg.MIN_PRICE: return False
    
    # æµå‹•æ€§ > 2000 è¬ç¾å…ƒ (ä½¿ç”¨ 20æ—¥å‡é‡è¨ˆç®—)
    avg_vol_20 = vol.tail(20).mean()
    dollar_vol = current_c * avg_vol_20
    if dollar_vol < cfg.MIN_DOLLAR_VOL_20D: return False # 20M USD

    # --- 2. ä½éšæ§åˆ¶ (Relative Position) ---
    # è‚¡åƒ¹éœ€é«˜æ–¼ 52 é€± (250å¤©) æœ€ä½åƒ¹çš„ 25%
    low_52w = low.tail(250).min()
    if current_c < (low_52w * cfg.LOW_52W_MULTIPLIER): return False

    # --- 3. æ•´ç†æœŸåˆ¤å®š (Consolidation Logic) ---
    # éå» 60 æ—¥å…§çš„é«˜ä½é»è½å·®ä¸å¾—è¶…é 30%
    high_60 = high.tail(60).max()
    low_60 = low.tail(60).min()
    consolidation_depth = (high_60 - low_60) / high_60
    if consolidation_depth > cfg.CONSOLIDATION_MAX_DEPTH_60D: return False

    # --- 4. æˆäº¤é‡ VDU (Volume Dry-Up) ---
    # è¿‘ 3 æ—¥å¹³å‡æˆäº¤é‡ < è¿‘ 20 æ—¥å¹³å‡æˆäº¤é‡ * 70%
    avg_vol_3 = vol.tail(3).mean()
    if avg_vol_3 >= (avg_vol_20 * cfg.VDU_MAX_RATIO): return False

    # --- 5. VCP Tightness (Dynamic Gap Tolerance - 10 Days) ---
    # æª¢æŸ¥è¿‘ 10 å¤© (åŸç‚º5å¤©ï¼Œæ”¹ç‚º10å¤©ä»¥æ¶µè“‹å®Œæ•´æ——å‹)
    check_days = cfg.VCP_TIGHT_DAYS
    recent_closes = close.tail(check_days).tolist()
    recent_opens = open_price.tail(check_days).tolist()
    
    gap_threshold = cfg.VCP_GAP_THRESHOLD # è§¸ç™¼åˆ¤å®šçš„è·³ç©ºé–€æª»
    valid_start_index = 0
    allowed_tightness = cfg.VCP_DEFAULT_TIGHTNESS # é è¨­å®¹è¨±éœ‡å¹… 3.5%
    
    for i in range(1, len(recent_closes)):
        prev_c = recent_closes[i-1]
        curr_o = recent_opens[i]
        curr_c = recent_closes[i]
        
        # A. æ›´æ–°è·³ç©ºåˆ¤æ–·: Open vs Prev Close
        gap_magnitude = (curr_o - prev_c) / prev_c
        
        if gap_magnitude > gap_threshold:
            valid_start_index = i # é‡ç½®èµ·é»è‡³è·³ç©ºç•¶å¤©
            
            # B. è¨ˆç®—ç•¶æ—¥æ¼²å¹… (Close vs Prev Close)
            day_gain_magnitude = (curr_c - prev_c) / prev_c
            
            # C. å–å…©è€…è¼ƒå¤§å€¼
            max_magnitude = max(gap_magnitude, day_gain_magnitude)
            
            # D. ç„¡æ¢ä»¶é€²ä½è‡³æ•´æ•¸ç™¾åˆ†æ¯” (ä¾‹å¦‚ 9.1% -> 10% -> 0.10)
            allowed_tightness = math.ceil(max_magnitude * 100) / 100.0
            
    adjusted_closes = recent_closes[valid_start_index:]
    
    # åªæœ‰ä¸€æ ¹Kç·šç„¡æ³•ç®—æ”¶æ–‚ï¼Œè¦–ç‚ºé€šé
    if len(adjusted_closes) < 2:
        pass 
    else:
        max_c = max(adjusted_closes)
        min_c = min(adjusted_closes)
        # éœ‡å¹…ç®—æ³•ï¼š(é«˜-ä½) / æœ€æ–°åƒ¹
        range_pct = (max_c - min_c) / current_c
        
        # ä½¿ç”¨å‹•æ…‹è¨ˆç®—çš„ allowed_tightness é€²è¡Œéæ¿¾
        if range_pct > allowed_tightness: return False 

    # --- 6. RS Fallen Angel Gate (vs QQQ) ---
    if qqq_close is not None:
        rs_pass, _ = compute_fallen_angel_rs_features(df, qqq_close)
        if not rs_pass:
            return False

    # --- 7. è¶¨å‹¢æ¿¾ç¶² (Trend) ---
    # è‚¡åƒ¹ > 50MA > 200MA
    sma50 = ta.sma(close, length=50)
    sma200 = ta.sma(close, length=200)
    if sma50 is None or sma200 is None: return False
    
    # ç¢ºä¿ 50MA èˆ‡ 200MA è¶¨å‹¢æ­£ç¢º
    if current_c < sma50.iloc[-1]: return False
    if sma50.iloc[-1] < sma200.iloc[-1]: return False

    return True

# --- D. å–®ä¸€è‚¡ç¥¨è¨ºæ–· (è©³ç´°å ±å‘Š) ---
def diagnose_single_stock(df, symbol, qqq_df=None):
    report = []
    is_pass = True
    df = df.dropna()
    
    if len(df) < 260:
        return False, f"âŒ è³‡æ–™ä¸è¶³ (< 260 days)"

    close = df['Close']
    vol = df['Volume']
    high = df['High']
    low = df['Low']
    open_price = df['Open']
    c_now = close.iloc[-1]
    
    # 1. åŸºç¤èˆ‡æµå‹•æ€§
    avg_vol_20 = vol.tail(20).mean()
    dollar_vol = c_now * avg_vol_20
    
    report.append(f"ğŸ”¹ **åŸºç¤é–€æª»**")
    if c_now >= 10:
        report.append(f"   âœ… è‚¡åƒ¹: ${c_now:.2f} (>= $10)")
    else:
        report.append(f"   âŒ è‚¡åƒ¹: ${c_now:.2f} (< $10)")
        is_pass = False
        
    if dollar_vol >= 20000000:
        report.append(f"   âœ… æ—¥å‡æˆäº¤é¡: ${dollar_vol/1000000:.1f}M (>= $20M)")
    else:
        report.append(f"   âŒ æ—¥å‡æˆäº¤é¡: ${dollar_vol/1000000:.1f}M (< $20M)")
        is_pass = False

    # 2. ä½éšæ§åˆ¶
    low_52w = low.tail(250).min()
    dist_low = (c_now - low_52w) / low_52w
    report.append(f"\nğŸ”¹ **ä½éš (vs 52W Low)**")
    if c_now >= low_52w * 1.25:
        report.append(f"   âœ… é«˜æ–¼å¹´ä½é»: +{dist_low*100:.1f}% (>= 25%)")
    else:
        report.append(f"   âŒ é›¢åº•å¤ªè¿‘: +{dist_low*100:.1f}% (< 25%)")
        is_pass = False

    # 3. æ•´ç†å‹æ…‹
    high_60 = high.tail(60).max()
    low_60 = low.tail(60).min()
    depth = (high_60 - low_60) / high_60
    report.append(f"\nğŸ”¹ **æ•´ç†å‹æ…‹ (60å¤©å…§)**")
    if depth <= 0.30:
        report.append(f"   âœ… ä¿®æ­£å¹…åº¦: -{depth*100:.1f}% (<= 30%)")
    else:
        report.append(f"   âŒ æ³¢å‹•éå¤§: -{depth*100:.1f}% (> 30%)")
        is_pass = False

    # 4. VDU (Volume Dry-Up)
    avg_vol_3 = vol.tail(3).mean()
    vdu_ratio = avg_vol_3 / avg_vol_20
    report.append(f"\nğŸ”¹ **æˆäº¤é‡ VDU**")
    if vdu_ratio < 0.70:
        report.append(f"   âœ… é‡ç¸®é¡¯è‘—: {vdu_ratio*100:.1f}% (Target < 70%)")
    else:
        report.append(f"   âŒ æœªè¦‹é‡ç¸®: {vdu_ratio*100:.1f}% (> 70%)")
        is_pass = False

    # 5. VCP Tightness (Dynamic Gap Logic - 10 Days)
    check_days = cfg.VCP_TIGHT_DAYS
    recent_closes = close.tail(check_days).tolist()
    recent_opens = open_price.tail(check_days).tolist()
    
    gap_threshold = cfg.VCP_GAP_THRESHOLD
    valid_start_index = 0
    allowed_tightness = 0.035 # Default
    gap_msg = ""

    for i in range(1, len(recent_closes)):
        prev_c = recent_closes[i-1]
        curr_o = recent_opens[i]
        curr_c = recent_closes[i]
        
        gap_mag = (curr_o - prev_c) / prev_c
        
        if gap_mag > gap_threshold:
            valid_start_index = i
            day_gain_mag = (curr_c - prev_c) / prev_c
            max_mag = max(gap_mag, day_gain_mag)
            allowed_tightness = math.ceil(max_mag * 100) / 100.0
            gap_msg = f"(Gap: {gap_mag*100:.1f}%, Allow: {allowed_tightness*100:.0f}%)"
            
    adjusted_closes = recent_closes[valid_start_index:]
    max_c = max(adjusted_closes)
    min_c = min(adjusted_closes)
    range_pct = (max_c - min_c) / c_now
    
    report.append(f"\nğŸ”¹ **æ”¶æ–‚åº¦ (Dynamic Gap, 10 Days)**")
    if valid_start_index > 0:
        report.append(f"   â„¹ï¸ åµæ¸¬åˆ°è·³ç©º {gap_msg}")
        
    if range_pct <= allowed_tightness:
        report.append(f"   âœ… 10æ—¥éœ‡å¹…: {range_pct*100:.2f}% (<= {allowed_tightness*100:.1f}%)")
    else:
        report.append(f"   âŒ éœ‡å¹…éå¤§: {range_pct*100:.2f}% (> {allowed_tightness*100:.1f}%)")
        is_pass = False

    # 6. RS (Fallen Angel) & Trend
    if qqq_df is not None and not qqq_df.empty:
        rs_pass, feat = compute_fallen_angel_rs_features(df, qqq_df['Close'])
        report.append(f"\nğŸ”¹ **Fallen Angel RS (vs QQQ)**")
        lp = feat.get('leader_peak_excess')
        nh = feat.get('rs_near_high_pct')
        ratio = feat.get('rs_dd_vs_price_dd')
        slope = feat.get('rs_ma20_slope')
        report.append(f"   â€¢ leader_peak_excess: {lp:.2f}%" if pd.notna(lp) else "   â€¢ leader_peak_excess: N/A")
        report.append(f"   â€¢ rs_near_high%: {nh:.2f}%" if pd.notna(nh) else "   â€¢ rs_near_high%: N/A")
        report.append(f"   â€¢ rs_dd_vs_price_dd: {ratio:.3f}" if pd.notna(ratio) else "   â€¢ rs_dd_vs_price_dd: N/A")
        report.append(f"   â€¢ RS_ma20_slope: {slope:.2f}%" if pd.notna(slope) else "   â€¢ RS_ma20_slope: N/A")

        if rs_pass:
            report.append("   âœ… RS Gate: PASS")
        else:
            report.append("   âŒ RS Gate: FAIL")
            is_pass = False

    sma50 = ta.sma(close, length=50).iloc[-1]
    sma200 = ta.sma(close, length=200).iloc[-1]
    
    if c_now > sma50 and sma50 > sma200:
        report.append(f"   âœ… å¤šé ­æ’åˆ— (P > 50MA > 200MA)")
    else:
        report.append(f"   âŒ è¶¨å‹¢ä¸ç¬¦")
        is_pass = False

    return is_pass, "\n".join(report)

# --- E. æƒæåŸ·è¡Œ ---
async def scan_market(target_date_str):
    try:
        if target_date_str:
            target_date = datetime.strptime(target_date_str, "%y%m%d")
        else:
            target_date = datetime.now()
        
        start_date = target_date - timedelta(days=cfg.HIST_CALENDAR_DAYS)
        end_date = target_date + timedelta(days=1)
        formatted_date = target_date.strftime('%Y-%m-%d')
        print(f"ğŸš€ é–‹å§‹æƒæ: {formatted_date}")

        # 1. åŸºæº– QQQï¼ˆBenchï¼‰
        qqq_data = yf_download_with_retry(cfg.BENCH_SYMBOL, start=start_date, end=end_date)
        if qqq_data.empty:
            print("âŒ ç„¡æ³•å–å¾— QQQ è³‡æ–™")
            return [], formatted_date

        qqq_close = qqq_data['Close'] if not isinstance(qqq_data.columns, pd.MultiIndex) else qqq_data['Close'][cfg.BENCH_SYMBOL]
        qqq_close = qqq_close.dropna()

        # 2. ç²å–ä¸¦éæ¿¾æ¸…å–®
        tickers = get_nasdaq_stock_list()
        
        batch_size = cfg.YF_BATCH_SIZE 
        rows = []

        for i in range(0, len(tickers), batch_size):
            batch = tickers[i:i+batch_size]
            try:
                data = yf_download_with_retry(batch, start=start_date, end=end_date, group_by='ticker', threads=True)
                if data.empty: continue

                for symbol in batch:
                    try:
                        if symbol not in data.columns.levels[0]: continue
                        
                        df = data[symbol].copy()
                        df.dropna(inplace=True)
                        if df.empty: continue
                        
                        # æ—¥æœŸæª¢æŸ¥
                        last_dt = df.index[-1].date()
                        if abs((last_dt - target_date.date()).days) > 1: continue
                        
                        if check_vcp_criteria(df, qqq_close):
                            rs_pass, feat = compute_fallen_angel_rs_features(df, qqq_close)
                            rows.append({
                                'Symbol': symbol,
                                'leader_peak_excess': feat.get('leader_peak_excess'),
                                'rs_near_high%': feat.get('rs_near_high_pct'),
                                'rs_dd_vs_price_dd': feat.get('rs_dd_vs_price_dd'),
                                'RS_ma20_slope': feat.get('rs_ma20_slope'),
                            })
                    except: continue
                
                await asyncio.sleep(cfg.YF_SLEEP_BETWEEN_BATCH_SEC)
            except Exception as e:
                print(f"Batch Error: {e}")
                continue

        return rows, formatted_date

    except Exception as e:
        traceback.print_exc()
        return [], target_date_str

# --- F. å–®ä¸€è¨ºæ–·å…¥å£ ---
async def fetch_and_diagnose(symbol_input, date_str):
    try:
        target_date = datetime.strptime(date_str, "%y%m%d")
        start_date = target_date - timedelta(days=cfg.HIST_CALENDAR_DAYS)
        end_date = target_date + timedelta(days=1)
        formatted_date = target_date.strftime('%Y-%m-%d')
        symbol = symbol_input.upper().strip().replace(".", "-")

        data = yf_download_with_retry([symbol, cfg.BENCH_SYMBOL], start=start_date, end=end_date, group_by='ticker')
        
        if symbol not in data.columns.levels[0]:
            return False, f"âŒ æ‰¾ä¸åˆ°: {symbol}", formatted_date
            
        df_stock = data[symbol].dropna()
        df_qqq = data[cfg.BENCH_SYMBOL].dropna()

        is_pass, report = diagnose_single_stock(df_stock, symbol, df_qqq)
        header = f"ğŸ” **è¨ºæ–·å ±å‘Š: {symbol}**\nğŸ“… {formatted_date}\n" + "-"*20 + "\n"
        return is_pass, header + report, formatted_date

    except Exception as e:
        return False, f"Error: {e}", date_str
